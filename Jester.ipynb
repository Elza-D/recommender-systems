{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN and SVD recommender systems for the Jester dataset by Elza Dabola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.sparse import csr_matrix \n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity # cosine distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances # euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the datasets and merging them into one\n",
    "df_items = pd.read_csv(\"jester_items.csv\")\n",
    "df_users = pd.read_csv('jester_ratings.csv')\n",
    "\n",
    "df = pd.merge(df_items, df_users, on='jokeId', how='outer')\n",
    "\n",
    "# Set the display format for float values\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jokeId       0\n",
       "jokeText     0\n",
       "userId      10\n",
       "rating      10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 10 nulls in userID and rating these will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping the nulls\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are no missing values\n"
     ]
    }
   ],
   "source": [
    "# checking for nulls \n",
    "a = df.isna().any()\n",
    "\n",
    "if a.any():\n",
    "    print('there are missing values')\n",
    "else:\n",
    "    print('there are no missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1761439 entries, 4 to 1761448\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   jokeId    int64  \n",
      " 1   jokeText  object \n",
      " 2   userId    float64\n",
      " 3   rating    float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 67.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking the types \n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of float types, let's check how the data looks before tranforming the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokeId</th>\n",
       "      <th>jokeText</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-9.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jokeId                                           jokeText  userId  rating\n",
       "4       5  Q.\\tWhat's O. J. Simpson's Internet address? \\...    1.00    0.22\n",
       "5       5  Q.\\tWhat's O. J. Simpson's Internet address? \\...    2.00   -9.69\n",
       "6       5  Q.\\tWhat's O. J. Simpson's Internet address? \\...    3.00   -9.84\n",
       "7       5  Q.\\tWhat's O. J. Simpson's Internet address? \\...    4.00   -5.81\n",
       "8       5  Q.\\tWhat's O. J. Simpson's Internet address? \\...    5.00    6.91"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UserId, of course, is a discrete variable, which will be transformed into an integer. However, the ratings are continuous, so their type won't be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1761439 entries, 4 to 1761448\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   jokeId    int64  \n",
      " 1   jokeText  object \n",
      " 2   userId    int32  \n",
      " 3   rating    float64\n",
      "dtypes: float64(1), int32(1), int64(1), object(1)\n",
      "memory usage: 60.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# changing the userId type to int\n",
    " \n",
    "df['userId'] = df['userId'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the min rating in the dataset is -10.0\n",
      "the max rating in the dataset is 10.0\n"
     ]
    }
   ],
   "source": [
    "# checking the range of ratings\n",
    "print('the min rating in the dataset is', df['rating'].min())\n",
    "print('the max rating in the dataset is', df['rating'].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokeId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1761439.00</td>\n",
       "      <td>1761439.00</td>\n",
       "      <td>1761439.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.71</td>\n",
       "      <td>32723.22</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.01</td>\n",
       "      <td>18280.11</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.00</td>\n",
       "      <td>17202.00</td>\n",
       "      <td>-2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.00</td>\n",
       "      <td>34808.00</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.00</td>\n",
       "      <td>47306.00</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.00</td>\n",
       "      <td>63978.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          jokeId     userId     rating\n",
       "count 1761439.00 1761439.00 1761439.00\n",
       "mean       70.71   32723.22       1.62\n",
       "std        46.01   18280.11       5.30\n",
       "min         5.00       1.00     -10.00\n",
       "25%        21.00   17202.00      -2.03\n",
       "50%        69.00   34808.00       2.22\n",
       "75%       112.00   47306.00       5.72\n",
       "max       150.00   63978.00      10.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how the data looks\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 59132 unique users and 140 unique jokes\n"
     ]
    }
   ],
   "source": [
    "# checking the nr unique users and items, code inspired from https://www.kaggle.com/code/razor08/knn-based-collaborative-filtering?scriptVersionId=81850169 \n",
    "nr_users = len(df.userId.unique())\n",
    "nr_items = len(df.jokeId.unique())\n",
    "\n",
    "print('there are {} unique users and {} unique jokes'.format(nr_users, nr_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## getting some initial insights into the data through visualisations \n",
    "\n",
    "# creating dataframes / variables for the graphs\n",
    "rating_count = pd.DataFrame(df.groupby('rating').size(), columns=['count'])\n",
    "joke_count = pd.DataFrame(df.groupby('jokeId').size(), columns=['count'])\n",
    "user_count = pd.DataFrame(df.groupby('userId').size(), columns=['count'])\n",
    "avg_rating_per_userid = df.groupby('userId')['rating'].mean()\n",
    "avg_rating_per_jokeid = df.groupby('jokeId')['rating'].mean()\n",
    "\n",
    "# creating figures and gridspec\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "\n",
    "# plotting the distribution of ratings\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.bar(x=rating_count.index, height=rating_count['count'])\n",
    "ax1.set_xlabel('Rating')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Graph 1: Distribution of Ratings')\n",
    "\n",
    "# plotting the distribution of average ratings per user\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.bar(avg_rating_per_userid.index, avg_rating_per_userid)\n",
    "ax2.set_xlabel('User ID')\n",
    "ax2.set_ylabel('Average Rating')\n",
    "ax2.set_title('Graph 2: Average Ratings per User')\n",
    "\n",
    "# plotting the distribution of average rating per joke\n",
    "ax3 = fig.add_subplot(gs[0,2])\n",
    "ax3.bar(avg_rating_per_jokeid.index, avg_rating_per_jokeid)\n",
    "ax3.set_xlabel('Joke ID')\n",
    "ax3.set_ylabel('Average Rating')\n",
    "ax3.set_title('Graph 3: Average Rating per Joke')\n",
    "\n",
    "# plotting the distribution of users\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "ax4.bar(x=user_count.index, height=user_count['count'])\n",
    "ax4.set_xlabel('User ID')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title('Graph 4: Distribution of Users')\n",
    "\n",
    "# plotting the distribution of jokes\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax5.bar(x=joke_count.index, height=joke_count['count'])\n",
    "ax5.set_xlabel('Joke ID')\n",
    "ax5.set_ylabel('Count')\n",
    "ax5.set_title('Graph 5: Distribution of Jokes')\n",
    "\n",
    "# setting font size and titles for all subplots\n",
    "for ax in fig.get_axes():\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.title.set_fontsize(14)\n",
    "    ax.xaxis.label.set_fontsize(14)\n",
    "    ax.yaxis.label.set_fontsize(14)\n",
    "\n",
    "# showing the final graphs\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 1 illustrates the distribution of ratings, revealing that the majority of jokes received ratings between approx. 0 and 5. Notably, there is a spike around the rating of 10, indicating a cluster of highly rated jokes. Ratings between approximately -8 and 0 are the least common in the dataset.\n",
    "\n",
    "Graph 2 illustrates the distribution of average ratings per user. Notably, there are three users who consistently give an average rating of approximately -10. Additionally, the majority of users tend to provide positive ratings, indicating an overall positive sentiment towards the jokes in the dataset.\n",
    "\n",
    "Graph 3 presents the distribution of average ratings per joke. It reveals that jokes numbered 0 to 20, along with 11 other jokes, receive an average negative rating. Conversely, the remaining jokes are rated positively. This suggests a differentiation in user perception, where a subset of jokes is generally perceived negatively while the majority receives positive ratings. Approx. joke 140 has the lowest average rating. \n",
    "\n",
    "Graph 4 represents the distribution of users and their rating activity. We observe 15 spikes, suggesting that there are 15 users who have rated approximately 130 jokes each. This indicates variations in user engagement and participation.\n",
    "\n",
    "Graph 5 showcases the distribution of jokes based on the number of times each joke has been rated. Notably, there is a spike between approximately 7 and 20, indicating that jokes numbered 7-20 have received significantly more ratings compared to the rest. However, it's interesting to note that jokes between 0 and 20 receive a negative average rating as seen in graph 3. This suggests that these particular jokes have garnered greater negative attention and feedback, surpassing the ratings of more than half of the other jokes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices\n",
    "_In this and following sections some parts of the code have been inspired by DataCamp course \"Building Recommendation Engines in Python\". In those sections it will be mentioned 'inspired by DataCamp'_\n",
    "<br>\n",
    "To be able to apply SVD and KNN models the data frame needs to be transformed into a matrix where items are columns, users are rows and ratings are values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jokeId   5     7     8     13    15    16    17    18    19    20   ...   141  \\\n",
      "userId                                                              ...         \n",
      "1       0.22 -9.28 -9.28 -6.78  0.88 -9.66 -9.03 -7.47 -8.72 -9.16  ...   NaN   \n",
      "2      -9.69  9.94  9.53  9.94  0.41  3.72  9.66 -2.69 -9.56 -9.12  ...   NaN   \n",
      "3      -9.84 -9.84 -7.22 -2.03 -9.94 -9.97 -9.88 -9.81 -9.78 -6.84  ...   NaN   \n",
      "4      -5.81 -4.50 -4.91   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "5       6.91  4.75 -5.91 -0.41 -4.03  3.88  6.22  5.66  6.09  5.41  ...   NaN   \n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "63974    NaN -4.44  1.53 -1.44 -9.16 -7.44  2.25  3.75  5.00   NaN  ...   NaN   \n",
      "63975    NaN  0.62  4.53  4.97 -3.38 -8.25 -7.78 -9.19  1.50   NaN  ...   NaN   \n",
      "63976    NaN -7.25  4.56 -5.59   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "63977    NaN -8.53 -8.44 -9.62  6.59 -6.25  9.31 -2.75  6.34   NaN  ...   NaN   \n",
      "63978    NaN -7.91 -7.59 -7.59 -6.38 -6.38 -6.38 -6.38 -1.81   NaN  ... -8.31   \n",
      "\n",
      "jokeId  142  143  144  145  146  147  148  149  150  \n",
      "userId                                               \n",
      "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "5       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "63974   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "63975   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "63976   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "63977   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "63978  7.84 8.91 8.50 8.38 8.94 8.28 8.78 8.78 7.56  \n",
      "\n",
      "[59132 rows x 140 columns]\n"
     ]
    }
   ],
   "source": [
    "# creating the matrix out of the dataset with items as columns, users as rows and values as the corresponding ratings\n",
    "matrix = df.pivot(index='userId', columns='jokeId', values='rating')\n",
    "print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems often encounter sparsity, as users typically do not rate all items in the matrix, resulting in null or zero values. Such missing or zero values can introduce inaccuracies and biases in recommendations, making it challenging for algorithms to identify meaningful patterns and relationships in the data. Thus, it is important to calculate the sparsity of the matrix and account for it when assessing the quality of the final recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the matrix is 78.72267614344662 % filled\n"
     ]
    }
   ],
   "source": [
    "# calculating the sparsity, inspired by DataCamp  \n",
    "nr_of_empty = matrix.isnull().values.sum()\n",
    "total_number = matrix.size\n",
    "sparsity = (nr_of_empty/total_number)*100\n",
    "print('the matrix is {} % filled'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# counting the number of not rated jokes\n",
    "not_rated_per_joke = matrix.isna().sum(axis=0)\n",
    "\n",
    "# plotting the frequency of not rated jokes\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x=not_rated_per_joke.index, height=not_rated_per_joke.values)\n",
    "ax.set_xlabel('Joke ID')\n",
    "ax.set_ylabel('Number of not rated jokes')\n",
    "ax.set_title('Frequency of not rated jokes')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above depicts the number of items with missing values. Notably, jokes numbered approximately 7 to 20 exhibit a relatively low number of missing values. This observation aligns with the findings from Graph 4, which illustrated that these particular jokes have received the highest number of ratings. Conversely, other jokes in the dataset tend to have a higher incidence of missing values. Additionaly, an interesting patter can be seen where there is a drop in missing values approx. every ten jokes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the sparsity of the matrix has been checked the nulls will be filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.22</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>-7.47</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.69</td>\n",
       "      <td>9.94</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.94</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.72</td>\n",
       "      <td>9.66</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>-9.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.84</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>-7.22</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>-9.94</td>\n",
       "      <td>-9.97</td>\n",
       "      <td>-9.88</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.81</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-4.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.91</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>3.88</td>\n",
       "      <td>6.22</td>\n",
       "      <td>5.66</td>\n",
       "      <td>6.09</td>\n",
       "      <td>5.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63974</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63975</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.97</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>-7.78</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63976</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.25</td>\n",
       "      <td>4.56</td>\n",
       "      <td>-5.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63977</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>-9.62</td>\n",
       "      <td>6.59</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>9.31</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63978</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.91</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.91</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.94</td>\n",
       "      <td>8.28</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.78</td>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59132 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId   5     7     8     13    15    16    17    18    19    20   ...   141  \\\n",
       "userId                                                              ...         \n",
       "1       0.22 -9.28 -9.28 -6.78  0.88 -9.66 -9.03 -7.47 -8.72 -9.16  ...  0.00   \n",
       "2      -9.69  9.94  9.53  9.94  0.41  3.72  9.66 -2.69 -9.56 -9.12  ...  0.00   \n",
       "3      -9.84 -9.84 -7.22 -2.03 -9.94 -9.97 -9.88 -9.81 -9.78 -6.84  ...  0.00   \n",
       "4      -5.81 -4.50 -4.91  0.00  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "5       6.91  4.75 -5.91 -0.41 -4.03  3.88  6.22  5.66  6.09  5.41  ...  0.00   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "63974   0.00 -4.44  1.53 -1.44 -9.16 -7.44  2.25  3.75  5.00  0.00  ...  0.00   \n",
       "63975   0.00  0.62  4.53  4.97 -3.38 -8.25 -7.78 -9.19  1.50  0.00  ...  0.00   \n",
       "63976   0.00 -7.25  4.56 -5.59  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "63977   0.00 -8.53 -8.44 -9.62  6.59 -6.25  9.31 -2.75  6.34  0.00  ...  0.00   \n",
       "63978   0.00 -7.91 -7.59 -7.59 -6.38 -6.38 -6.38 -6.38 -1.81  0.00  ... -8.31   \n",
       "\n",
       "jokeId  142  143  144  145  146  147  148  149  150  \n",
       "userId                                               \n",
       "1      0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "2      0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "3      0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "4      0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "5      0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "63974  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "63975  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "63976  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "63977  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "63978  7.84 8.91 8.50 8.38 8.94 8.28 8.78 8.78 7.56  \n",
       "\n",
       "[59132 rows x 140 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling the nulls with 0\n",
    "matrix.fillna(0, inplace=True)\n",
    "matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSys: SVD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the matrix needs to be split into train (to train the system), test (to evaluate the final predictions). For SVD 20% of rows will be allocated to the test set and 80% to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20% of total rows: 11826\n",
      "shape of the test set: (11826, 140)\n",
      "shape of the train set: (47306, 140)\n"
     ]
    }
   ],
   "source": [
    "## splitting the dataset\n",
    "\n",
    "# calculating 20% of rows \n",
    "rows_20_percent = int(0.2 * len(matrix))\n",
    "print('20% of total rows:', rows_20_percent)\n",
    "\n",
    "# shuffiling the rows of the matrix\n",
    "matrix_shuffled = matrix.sample(frac=1, random_state=42)\n",
    "\n",
    "# extracting the test set\n",
    "test = matrix_shuffled.iloc[:rows_20_percent, :].copy() # first 20% of rows and all columns\n",
    "print('shape of the test set:', test.shape)\n",
    "\n",
    "# extracting the train set\n",
    "train = matrix_shuffled.iloc[rows_20_percent:, :].copy() # last 80% of rows and all columns\n",
    "print('shape of the train set:', train.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double checking if the split was done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.59</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-9.97</td>\n",
       "      <td>9.97</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>9.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63051</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>-3.97</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>2.28</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.94</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36205</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-8.47</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37168</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.31</td>\n",
       "      <td>-7.31</td>\n",
       "      <td>-8.12</td>\n",
       "      <td>-9.69</td>\n",
       "      <td>4.62</td>\n",
       "      <td>6.34</td>\n",
       "      <td>8.41</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>-5.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId  5     7     8     13    15    16   17    18   19   20   ...   141  \\\n",
       "userId                                                          ...         \n",
       "1783   0.00 -9.59 -1.38 -9.78 -1.56 -9.97 9.97 -9.81 9.94 0.00  ... -9.81   \n",
       "8048   0.00  8.00  4.59  4.53  0.00  0.00 0.00  0.00 0.00 0.00  ...  0.00   \n",
       "63051  0.00 -9.75 -3.97 -9.78  2.28  9.88 9.94 -9.78 2.34 0.00  ...  0.00   \n",
       "36205  0.00 -8.50  1.03 -1.72  4.25 -8.47 2.53  4.25 2.19 0.00  ...  0.00   \n",
       "37168  0.00 -6.31 -7.31 -8.12 -9.69  4.62 6.34  8.41 4.50 0.00  ...  0.00   \n",
       "\n",
       "jokeId   142  143  144   145  146   147   148  149  150  \n",
       "userId                                                   \n",
       "1783    9.97 0.00 0.00  9.97 0.00  0.00  0.00 9.94 0.00  \n",
       "8048    0.00 0.00 0.00  0.00 0.00  0.00  0.00 0.00 0.00  \n",
       "63051  -9.53 0.00 0.00  0.00 0.00  0.00 -9.53 0.00 0.00  \n",
       "36205   0.00 0.00 0.00  0.00 0.00  0.00  0.00 0.00 0.00  \n",
       "37168   1.00 1.78 0.00 -7.44 0.00 -4.88 -5.19 0.00 4.41  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.59</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-9.97</td>\n",
       "      <td>9.97</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>9.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63051</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>-3.97</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>2.28</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.94</td>\n",
       "      <td>-9.78</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36205</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-8.47</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37168</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.31</td>\n",
       "      <td>-7.31</td>\n",
       "      <td>-8.12</td>\n",
       "      <td>-9.69</td>\n",
       "      <td>4.62</td>\n",
       "      <td>6.34</td>\n",
       "      <td>8.41</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>-5.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId  5     7     8     13    15    16   17    18   19   20   ...   141  \\\n",
       "userId                                                          ...         \n",
       "1783   0.00 -9.59 -1.38 -9.78 -1.56 -9.97 9.97 -9.81 9.94 0.00  ... -9.81   \n",
       "8048   0.00  8.00  4.59  4.53  0.00  0.00 0.00  0.00 0.00 0.00  ...  0.00   \n",
       "63051  0.00 -9.75 -3.97 -9.78  2.28  9.88 9.94 -9.78 2.34 0.00  ...  0.00   \n",
       "36205  0.00 -8.50  1.03 -1.72  4.25 -8.47 2.53  4.25 2.19 0.00  ...  0.00   \n",
       "37168  0.00 -6.31 -7.31 -8.12 -9.69  4.62 6.34  8.41 4.50 0.00  ...  0.00   \n",
       "\n",
       "jokeId   142  143  144   145  146   147   148  149  150  \n",
       "userId                                                   \n",
       "1783    9.97 0.00 0.00  9.97 0.00  0.00  0.00 9.94 0.00  \n",
       "8048    0.00 0.00 0.00  0.00 0.00  0.00  0.00 0.00 0.00  \n",
       "63051  -9.53 0.00 0.00  0.00 0.00  0.00 -9.53 0.00 0.00  \n",
       "36205   0.00 0.00 0.00  0.00 0.00  0.00  0.00 0.00 0.00  \n",
       "37168   1.00 1.78 0.00 -7.44 0.00 -4.88 -5.19 0.00 4.41  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_shuffled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shuffled matrix and test matrix have the same first 5 rows which means the split was done correctly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latent factor\n",
    "\n",
    "By default svds package takes 6 as the latent factor. This is the hyperparameter of SVD. The optimal latent factor needs to found to make sure the most precise predictions are made. To do so the train matrix will be used. 5 different latent factors will be tested (6(default), 12, 18, 24, 30)\n",
    "\n",
    "Steps for each latent factor:\n",
    "1. take out 100 users of the matrix and store it (this is the y)\n",
    "2. find the 3 matrices (U, sigma, Vt) from x (train matrix)\n",
    "3. calculate the dot product between U and sigma and Vt to get the matrix back (x_hat)\n",
    "4. take out the predicted ratings of the 100 users taken out before (y_hat)\n",
    "5. calculate the RMSE using y and y_hat\n",
    "<br>\n",
    "Repeat this process with another set of 100 users (total 20 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding all unique userIds and storing in a list \n",
    "user_ids = train.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57679</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36056</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>-6.88</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36590</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-7.16</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.72</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46335</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.56</td>\n",
       "      <td>-7.34</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>-7.50</td>\n",
       "      <td>-9.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43959</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-5.66</td>\n",
       "      <td>3.66</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.41</td>\n",
       "      <td>7.41</td>\n",
       "      <td>8.06</td>\n",
       "      <td>2.31</td>\n",
       "      <td>6.72</td>\n",
       "      <td>8.66</td>\n",
       "      <td>8.09</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.69</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51520</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-6.19</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>6.62</td>\n",
       "      <td>3.78</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.62</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41824</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.19</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>6.12</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>7.44</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62013</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.97</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>-8.03</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>7.53</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>6.62</td>\n",
       "      <td>3.56</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId  5     7     8     13    15    16    17    18    19   20   ...   141  \\\n",
       "userId                                                            ...         \n",
       "57679  0.00 -3.69 -4.31  1.31  0.00  0.00  0.00  0.00  0.00 0.00  ...  0.00   \n",
       "36056  0.00  2.16 -6.53 -6.88 -4.22 -6.84 -0.81 -1.25  0.22 0.00  ...  0.00   \n",
       "36590  0.00 -6.59  0.50  0.41 -0.47  4.62 -7.16 -9.75 -9.84 0.00  ...  0.00   \n",
       "46335  0.00 -4.56 -7.34 -8.00 -7.50 -9.34  0.00  0.00  0.00 0.00  ...  0.00   \n",
       "43959  0.00 -4.28  3.66  1.59  1.09 -5.66  3.66  5.75  6.75 0.00  ... -6.41   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  ...   ...   \n",
       "51520  0.00 -6.25 -6.19 -3.28 -7.00 -6.62 -6.62 -6.62 -6.66 0.00  ...  0.00   \n",
       "30596  0.00  0.53  6.62  3.78 -0.22 -3.06  1.41  1.62  6.50 0.00  ...  0.00   \n",
       "41824  0.00 -3.09  0.12 -3.59  0.53  1.91 -2.41  0.12 -2.69 0.00  ... -1.72   \n",
       "14268  0.00 -7.19 -8.25  6.12 -6.84  7.44  0.09  0.00  0.00 0.00  ...  0.00   \n",
       "62013  0.00  3.00  5.97 -9.84 -8.03 -3.09  7.53  1.31  1.00 0.00  ...  0.00   \n",
       "\n",
       "jokeId   142   143   144   145   146   147   148  149   150  \n",
       "userId                                                       \n",
       "57679   0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00  0.00  \n",
       "36056  -3.69 -3.44 -1.66 -2.66 -2.53 -0.72 -0.41 1.16  0.75  \n",
       "36590  -8.31 -8.50 -6.78 -9.09  0.00 -9.72 -6.50 0.94 -8.44  \n",
       "46335   0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00  0.00  \n",
       "43959   7.41  8.06  2.31  6.72  8.66  8.09  7.31 6.69  2.62  \n",
       "...      ...   ...   ...   ...   ...   ...   ...  ...   ...  \n",
       "51520   0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00  0.00  \n",
       "30596   0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00  0.00  \n",
       "41824   0.91  2.22 -2.41 -0.72 -2.78  0.12  0.03 0.06  1.59  \n",
       "14268   0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00  0.00  \n",
       "62013   0.00 -3.16 -4.94  0.28  0.00 -3.38  6.62 3.56  6.78  \n",
       "\n",
       "[100 rows x 140 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  randomly selectings 100 users ids from user_ids list \n",
    "y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "# extracting the corresponding rows from train matrix\n",
    "y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the 3 matrices out using the default latent factor (=6)\n",
    "U, sigma, Vt = svds(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming sigma to a diagonal matrix\n",
    "sigma = np.diag(sigma)\n",
    "# getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "X_hat = U.dot(sigma.dot(Vt))\n",
    "# creating a df of the results - recalculated matrix with the predicted ratings \n",
    "X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62013</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-8.70</td>\n",
       "      <td>-4.09</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>1.51</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38824</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-6.76</td>\n",
       "      <td>-9.64</td>\n",
       "      <td>7.21</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20084</th>\n",
       "      <td>0.03</td>\n",
       "      <td>7.53</td>\n",
       "      <td>2.58</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55390</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.34</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-4.24</td>\n",
       "      <td>-8.23</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>-6.92</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-2.77</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-2.91</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61410</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.01</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28473</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43354</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>-5.43</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-10.25</td>\n",
       "      <td>-5.43</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4.18</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.95</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.59</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57966</th>\n",
       "      <td>0.02</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>-5.51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25335</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-3.19</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId   5     7     8      13    15    16    17    18    19    20   ...  \\\n",
       "userId                                                               ...   \n",
       "62013  -0.02  6.52  0.43  -8.70 -4.09 -2.84  0.74  1.84  2.57 -0.01  ...   \n",
       "38824   0.00 -0.99  1.28   2.05 -6.76 -9.64  7.21 -3.36  3.89  0.00  ...   \n",
       "32708  -0.01 -0.30 -0.36  -1.91 -3.29 -2.42  4.64  0.36  3.60  0.01  ...   \n",
       "20084   0.03  7.53  2.58  -1.22  0.13 -0.32  0.20  0.10 -0.19  0.01  ...   \n",
       "55390  -0.01  2.34 -0.35  -0.72 -4.24 -8.23 -5.21 -6.92 -6.25 -0.07  ...   \n",
       "...      ...   ...   ...    ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "61410   0.00 -1.96  1.50   4.01 -0.92 -2.34  4.61 -0.11  3.05  0.01  ...   \n",
       "28473   0.00  0.68  0.63   0.36 -1.09 -1.46  1.89 -0.28  1.16  0.00  ...   \n",
       "43354  -0.08 -5.43 -5.50 -10.25 -5.43 -2.52 -1.91  1.00  1.22 -0.03  ...   \n",
       "57966   0.02  4.94  1.33  -1.41 -3.54 -5.51  0.18 -3.06 -1.12 -0.01  ...   \n",
       "25335   0.02  2.86  3.80   5.98  0.81 -3.19  0.38 -2.11 -1.06  0.00  ...   \n",
       "\n",
       "jokeId   141   142   143   144   145   146   147   148   149   150  \n",
       "userId                                                              \n",
       "62013  -1.49  0.21  3.55  1.10  2.33 -0.61  1.51  4.42  1.95  5.15  \n",
       "38824  -0.09  1.52  0.95  0.05  1.18  0.09 -0.09  0.68  0.49 -0.28  \n",
       "32708  -0.11  0.60  0.46 -0.19  0.47 -0.07 -0.12  0.23  0.10 -0.21  \n",
       "20084   0.07 -0.13 -0.11  0.03 -0.10  0.02 -0.04  0.02 -0.00  0.09  \n",
       "55390  -1.07 -2.77 -2.98 -2.32 -2.81 -1.81 -2.78 -2.91 -2.81 -2.47  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "61410  -0.18  0.47  0.12 -0.31  0.20 -0.22 -0.40 -0.11 -0.18 -0.46  \n",
       "28473   0.01  0.26  0.07 -0.07  0.13 -0.01 -0.11 -0.01 -0.00 -0.21  \n",
       "43354  -1.29  0.74  4.18  1.64  2.95 -0.15  2.27  4.96  2.59  5.53  \n",
       "57966  -0.03  0.11 -0.03 -0.03  0.10 -0.03 -0.19  0.07  0.02 -0.14  \n",
       "25335  -0.06  0.12 -0.09  0.09  0.03 -0.05 -0.17  0.05 -0.00  0.04  \n",
       "\n",
       "[100 rows x 140 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the predicted results of the 100 users\n",
    "y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with k=6:  2.8689908525567245\n"
     ]
    }
   ],
   "source": [
    "# calculating the rmse\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "print(\"Mean squared error with k=6: \", rmse_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the above needs to be done 19 more times and then the average rmse will be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with k=6:  2.9125180654915033\n"
     ]
    }
   ],
   "source": [
    "## calcluating the average RMSE for the defaul latent factor \n",
    "\n",
    "# setting the nr of interactions\n",
    "num_interactions = 20\n",
    "\n",
    "# initializing the rmse list\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(num_interactions):\n",
    "    #  randomly selectings 100 users ids from user_ids list\n",
    "    y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "    # extracting the corresponding rows from train matrix\n",
    "    y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "    # finding the 3 matrices out using the default latent factor (=6)\n",
    "    U, sigma, Vt = svds(train, k=6) \n",
    "\n",
    "    # transforming sigma to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "    X_hat = U.dot(sigma.dot(Vt))\n",
    "    # creating a df of the results - recalculated matrix with the predicted ratings \n",
    "    X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)\n",
    "\n",
    "    # storing the predicted results of the 100 users\n",
    "    y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "    # calculating the rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# calculating the average rmse for latent factor 6\n",
    "avg_rmse_6 = sum(rmse_list) / len(rmse_list)\n",
    "print(\"Average RMSE with k=6: \", avg_rmse_6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the above will be repeated with different latent factor values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with k=12:  3.0947630879186008\n"
     ]
    }
   ],
   "source": [
    "## calcluating the average RMSE for latent factor = 12\n",
    "\n",
    "# setting the nr of interactions\n",
    "num_interactions = 20\n",
    "\n",
    "# initializing the rmse list\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(num_interactions):\n",
    "    #  randomly selectings 100 users ids from user_ids list\n",
    "    y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "    # extracting the corresponding rows from train matrix\n",
    "    y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "    # finding the 3 matrices out using latent factor = 12)\n",
    "    U, sigma, Vt = svds(train, k=12) \n",
    "\n",
    "    # transforming sigma to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "    X_hat = U.dot(sigma.dot(Vt))\n",
    "    # creating a df of the results - recalculated matrix with the predicted ratings \n",
    "    X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)\n",
    "\n",
    "    # storing the predicted results of the 100 users\n",
    "    y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "    # calculating the rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# calculating the average rmse for latent factor 12\n",
    "avg_rmse_12 = sum(rmse_list) / len(rmse_list)\n",
    "print(\"Average RMSE with k=12: \", avg_rmse_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with k=18:  3.0380556780194654\n"
     ]
    }
   ],
   "source": [
    "## calcluating the average RMSE for latent factor = 18\n",
    "\n",
    "# setting the nr of interactions\n",
    "num_interactions = 20\n",
    "\n",
    "# initializing the rmse list\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(num_interactions):\n",
    "    #  randomly selectings 100 users ids from user_ids list\n",
    "    y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "    # extracting the corresponding rows from train matrix\n",
    "    y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "    # finding the 3 matrices out using latent factor = 18)\n",
    "    U, sigma, Vt = svds(train, k = 18) \n",
    "\n",
    "    # transforming sigma to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "    X_hat = U.dot(sigma.dot(Vt))\n",
    "    # creating a df of the results - recalculated matrix with the predicted ratings \n",
    "    X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)\n",
    "\n",
    "    # storing the predicted results of the 100 users\n",
    "    y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "    # calculating the rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# calculating the average rmse for latent factor 18\n",
    "avg_rmse_18 = sum(rmse_list) / len(rmse_list)\n",
    "print(\"Average RMSE with k=18: \", avg_rmse_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with k=24:  3.2113039347926593\n"
     ]
    }
   ],
   "source": [
    "## calcluating the average RMSE for latent factor = 24\n",
    "\n",
    "# setting the nr of interactions\n",
    "num_interactions = 20\n",
    "\n",
    "# initializing the rmse list\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(num_interactions):\n",
    "    #  randomly selectings 100 users ids from user_ids list\n",
    "    y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "    # extracting the corresponding rows from train matrix\n",
    "    y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "    # finding the 3 matrices out using latent factor = 24)\n",
    "    U, sigma, Vt = svds(train, k=24) \n",
    "\n",
    "    # transforming sigma to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "    X_hat = U.dot(sigma.dot(Vt))\n",
    "    # creating a df of the results - recalculated matrix with the predicted ratings \n",
    "    X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)\n",
    "\n",
    "    # storing the predicted results of the 100 users\n",
    "    y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "    # calculating the rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# calculating the average rmse for latent factor 24\n",
    "avg_rmse_24 = sum(rmse_list) / len(rmse_list)\n",
    "print(\"Average RMSE with k=24: \", avg_rmse_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with k=30:  3.1572876881459733\n"
     ]
    }
   ],
   "source": [
    "## calcluating the average RMSE for latent factor = 30\n",
    "\n",
    "# setting the nr of interactions\n",
    "num_interactions = 20\n",
    "\n",
    "# initializing the rmse list\n",
    "rmse_list = []\n",
    "\n",
    "for i in range(num_interactions):\n",
    "    #  randomly selectings 100 users ids from user_ids list\n",
    "    y_1_user_ids = random.sample(list(user_ids), 100)\n",
    "    # extracting the corresponding rows from train matrix\n",
    "    y_1 = train.loc[y_1_user_ids]\n",
    "\n",
    "    # finding the 3 matrices out using latent factor = 30)\n",
    "    U, sigma, Vt = svds(train, k=30) \n",
    "\n",
    "    # transforming sigma to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # getting the predicted ratings by calculating back the matrix from U, sigma and Vt\n",
    "    X_hat = U.dot(sigma.dot(Vt))\n",
    "    # creating a df of the results - recalculated matrix with the predicted ratings \n",
    "    X_hat = pd.DataFrame(X_hat, index = train.index, columns = train.columns)\n",
    "\n",
    "    # storing the predicted results of the 100 users\n",
    "    y_hat = X_hat.loc[X_hat.index.isin(y_1_user_ids)]\n",
    "\n",
    "    # calculating the rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_1, y_hat))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# calculating the average rmse for latent factor 30\n",
    "avg_rmse_30 = sum(rmse_list) / len(rmse_list)\n",
    "print(\"Average RMSE with k=30: \", avg_rmse_30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average root mean square error (RMSE) values for each value of k have been computed. To facilitate further analysis, these values will be stored in a dictionary. The purpose of storing them in a dictionary is to identify the k value that corresponds to the smallest average RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latent factor with the smallest average RMSE is 6 with a value of 2.9125180654915033\n"
     ]
    }
   ],
   "source": [
    "# creating a dictionary to store all average rmse values\n",
    "rmse_dict_svd = {6: avg_rmse_6, 12: avg_rmse_12, 18: avg_rmse_18, 24: avg_rmse_24, 30: avg_rmse_30}\n",
    "# finding the lowesr average rmse\n",
    "min_rmse_name = min(rmse_dict_svd, key=rmse_dict_svd.get)\n",
    "print(f\"The latent factor with the smallest average RMSE is {min_rmse_name} with a value of {rmse_dict_svd[min_rmse_name]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the optimal latent factor is found it will be used to make the final prediction to find top 5 most similar jokes to a specified joke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting out the 3 matrices using the best latent factor identified above\n",
    "U, sigma, Vt = svds(train, k=min_rmse_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar jokes to joke 0 are:\n",
      "joke 2 with similarity 0.8116643771740683\n",
      "joke 1 with similarity 0.7939595938812365\n",
      "joke 9 with similarity 0.5009510651221221\n",
      "joke 113 with similarity 0.46368092275407424\n",
      "joke 47 with similarity 0.4581675999830554\n"
     ]
    }
   ],
   "source": [
    "## finding the most similar items to a specified item, code inspired from https://machinelearningmastery.com/using-singular-value-decomposition-to-build-a-recommender-system/ \n",
    "\n",
    "# calculating the cosine similarity between two vectors\n",
    "def cosine_similarity(V, U):\n",
    "    return (V @ U) / (np.linalg.norm(V) * np.linalg.norm(U))\n",
    "\n",
    "# specifying the nr of similar items we want to see\n",
    "num_similar = 5\n",
    "\n",
    "# finding the most similar items to the input item based on the latent factors in Vt\n",
    "def find_similar_items(item_id, Vt, num_similar):\n",
    "    similarities = []\n",
    "    # calculating the cosine similarity between the input item and all other items\n",
    "    for col in range(Vt.shape[1]):\n",
    "        # exclude the input item from the results\n",
    "        if col != item_id: \n",
    "            similarity = cosine_similarity(Vt[:, item_id], Vt[:, col])\n",
    "            similarities.append((col, similarity))\n",
    "    # sorting the similarities in descending order and return the most similar items\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:num_similar]\n",
    "\n",
    "# spcifying the item we want to find the most similar ones to - this is the picked item \n",
    "item_id = 0 \n",
    "\n",
    "# finding the most similar items\n",
    "similar_items = find_similar_items(item_id, Vt, num_similar)\n",
    "print(f\"The {num_similar} most similar jokes to joke {item_id} are:\")\n",
    "\n",
    "for j_id, similarity in similar_items:\n",
    "    print(f\"joke {j_id} with similarity {similarity}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSys: KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the test matrix created above will be split fursther into validation (50% rows of test) and test (50% rows of test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of total rows: 5913\n",
      "shape of the test set: (5913, 140)\n",
      "shape of the valid set: (5913, 140)\n"
     ]
    }
   ],
   "source": [
    "test_20 = test\n",
    "\n",
    "## splitting the test_20 set into test and valid\n",
    "\n",
    "# calcluating 50% of rows\n",
    "rows_50_percent = int(len(test_20)/2)\n",
    "print('50% of total rows:', rows_50_percent)\n",
    "\n",
    "# extracting the test set\n",
    "test = test_20.iloc[:rows_50_percent, :].copy() # first 50% of rows and all columns\n",
    "print('shape of the test set:', test.shape)\n",
    "\n",
    "# extracting the valid set\n",
    "valid = test_20.iloc[rows_50_percent:, :].copy() # last 50% of rows and all columns\n",
    "print('shape of the valid set:', valid.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN will be applied to predict how a user might fell about an item it hasn't interacted with based on ratings similar users gave. First predictions will be made using cosine similarity and k=3\n",
    "\n",
    "Steps to do execute KNN by hand:\n",
    "1. creating the user-user similarity matrix\n",
    "2. finding k closest neighbors to a specified user\n",
    "3. find ratings the k closest neighbors gave to items and calculate the mean \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# finding the similarities between all users on the train matrix, code inspired from DataCamp\n",
    "similarities_user_train = cosine_similarity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>58829</th>\n",
       "      <th>26492</th>\n",
       "      <th>31774</th>\n",
       "      <th>8211</th>\n",
       "      <th>38341</th>\n",
       "      <th>24162</th>\n",
       "      <th>42680</th>\n",
       "      <th>58786</th>\n",
       "      <th>42175</th>\n",
       "      <th>62061</th>\n",
       "      <th>...</th>\n",
       "      <th>18424</th>\n",
       "      <th>6903</th>\n",
       "      <th>59360</th>\n",
       "      <th>12382</th>\n",
       "      <th>48027</th>\n",
       "      <th>58760</th>\n",
       "      <th>41036</th>\n",
       "      <th>947</th>\n",
       "      <th>17345</th>\n",
       "      <th>61036</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58829</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26492</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31774</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8211</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38341</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId  58829  26492  31774  8211   38341  24162  42680  58786  42175  62061  \\\n",
       "userId                                                                         \n",
       "58829    1.00  -0.01   0.28   0.02   0.09   0.12  -0.17   0.12  -0.43   0.37   \n",
       "26492   -0.01   1.00   0.17   0.75   0.38  -0.58  -0.00  -0.04   0.29   0.26   \n",
       "31774    0.28   0.17   1.00  -0.10   0.13  -0.10   0.14  -0.04  -0.16   0.27   \n",
       "8211     0.02   0.75  -0.10   1.00   0.36  -0.44  -0.02   0.15   0.36   0.12   \n",
       "38341    0.09   0.38   0.13   0.36   1.00  -0.22  -0.01   0.21   0.12   0.22   \n",
       "\n",
       "userId  ...  18424  6903   59360  12382  48027  58760  41036  947    17345  \\\n",
       "userId  ...                                                                  \n",
       "58829   ...   0.39   0.15   0.19   0.28   0.15   0.08  -0.06   0.02   0.07   \n",
       "26492   ...  -0.36   0.17  -0.10  -0.19  -0.06   0.48  -0.60   0.08   0.10   \n",
       "31774   ...  -0.01  -0.00   0.15   0.41   0.18   0.20   0.00   0.16   0.12   \n",
       "8211    ...  -0.16   0.22  -0.03  -0.05   0.03   0.60  -0.45   0.06   0.03   \n",
       "38341   ...   0.08   0.32   0.20   0.09   0.12   0.30  -0.17  -0.10   0.05   \n",
       "\n",
       "userId  61036  \n",
       "userId         \n",
       "58829   -0.09  \n",
       "26492   -0.20  \n",
       "31774    0.00  \n",
       "8211    -0.30  \n",
       "38341   -0.11  \n",
       "\n",
       "[5 rows x 47306 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the above similarities in a dataframe, code inspired from DataCamp\n",
    "user_cosine_similarity_train = pd.DataFrame(similarities_user_train, index=train.index, columns=train.index)\n",
    "user_cosine_similarity_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above seems to be correct as similarities between the user itself is equal to 1. Now we can find most similar user to a specified user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "58829    0.44\n",
       "26492   -0.21\n",
       "31774    0.13\n",
       "8211    -0.06\n",
       "38341    0.05\n",
       "         ... \n",
       "58760   -0.02\n",
       "41036    0.13\n",
       "947      0.01\n",
       "17345    0.22\n",
       "61036    0.02\n",
       "Name: 10, Length: 47306, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the similarity values for a specific user, in this case user 10, code inspired from DataCamp\n",
    "cosine_similarity_series = user_cosine_similarity_train.loc[10]\n",
    "cosine_similarity_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "10       1.00\n",
       "57039    0.52\n",
       "63044    0.52\n",
       "17444    0.52\n",
       "51376    0.52\n",
       "         ... \n",
       "49684   -0.44\n",
       "52981   -0.45\n",
       "56702   -0.46\n",
       "58127   -0.47\n",
       "45858   -0.49\n",
       "Name: 10, Length: 47306, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the values from highest to lowest, so for the 3 highest neighbors the rating will be calculated, code inspired from DataCamp\n",
    "ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "ordered_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57039</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.94</td>\n",
       "      <td>3.50</td>\n",
       "      <td>-6.69</td>\n",
       "      <td>9.06</td>\n",
       "      <td>-5.19</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63044</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.16</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>7.66</td>\n",
       "      <td>-4.91</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>4.91</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.94</td>\n",
       "      <td>8.47</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17444</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.34</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>5.91</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId  5     7     8     13    15    16   17    18    19   20   ...  141  \\\n",
       "userId                                                           ...        \n",
       "57039  0.00 -5.12  0.16  9.94  3.50 -6.69 9.06 -5.19  3.41 0.00  ... 0.00   \n",
       "63044  0.00 -5.16 -5.91  7.66 -4.91 -4.78 4.91 -4.38  7.34 0.00  ... 0.00   \n",
       "17444  0.00  6.03  5.34 -6.25  2.47 -6.78 5.91 -3.16 -1.75 0.00  ... 0.00   \n",
       "\n",
       "jokeId  142  143  144  145  146  147  148  149  150  \n",
       "userId                                               \n",
       "57039  0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "63044  8.62 8.72 0.00 7.88 0.00 0.00 7.94 8.47 8.00  \n",
       "17444  0.00 0.00 0.00 9.47 0.00 0.00 9.44 0.00 5.50  \n",
       "\n",
       "[3 rows x 140 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding 3 most similar users (k=3), code inspired from DataCamp\n",
    "nearest_neighbors = ordered_similarities[1:4].index\n",
    "\n",
    "# finding the ratings the 3 closes neighbors gave\n",
    "neighbor_ratings = matrix.reindex(nearest_neighbors)\n",
    "\n",
    "neighbor_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcluating the mean of closest neighbor ratings and sorting from highest to lowest, code inspired from DataCamp\n",
    "predicted_ratings = neighbor_ratings.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items recommender to user 10 in order: jokeId\n",
      "63    8.55\n",
      "50    8.24\n",
      "53    8.21\n",
      "62    8.13\n",
      "89    8.04\n",
      "      ... \n",
      "7    -1.42\n",
      "29   -1.78\n",
      "23   -2.34\n",
      "18   -4.24\n",
      "16   -6.08\n",
      "Length: 140, dtype: float64\n",
      "nearest neighbors on which the prediction was based on: Int64Index([57039, 63044, 17444], dtype='int64', name='userId')\n"
     ]
    }
   ],
   "source": [
    "print('items recommender to user 10 in order:', predicted_ratings)\n",
    "print('nearest neighbors on which the prediction was based on:', nearest_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how a prediction is made for one specific user. Now all user ratings will be predictied using the same steps except looping through all user ids in train matrix and storing the ratings in all_user_predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the user ids in the train set \n",
    "train_user_ids = train.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a function to make recommendations for any user\n",
    "\n",
    "def make_recommendations(user_id, train_data, user_similarity_data, num_neighbors, num_recommendations):\n",
    "    # finding the similarity values for all users\n",
    "    cosine_similarity_series = user_similarity_data.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding k most similar users\n",
    "    nearest_neighbors = ordered_similarities[1:num_neighbors+1].index\n",
    "\n",
    "    # finding the ratings of the k closest neighbors\n",
    "    neighbor_ratings = train_data.reindex(nearest_neighbors)\n",
    "    \n",
    "    # calculating the mean of the ratings of k closest neighbors\n",
    "    predicted_ratings = neighbor_ratings.mean().sort_values(ascending=False)[:num_recommendations]\n",
    "\n",
    "    return predicted_ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to find recommendations for a specific user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recommended to user 10 in order:\n",
      "jokeId\n",
      "63   8.55\n",
      "50   8.24\n",
      "53   8.21\n",
      "62   8.13\n",
      "89   8.04\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## finding recommendations for a specific user\n",
    "\n",
    "user_id = 10\n",
    "num_neighbors = 3\n",
    "num_recommendations = 5\n",
    "predicted_ratings = make_recommendations(user_id, train, user_cosine_similarity_train, num_neighbors, num_recommendations)\n",
    "\n",
    "print('Items recommended to user {} in order:'.format(user_id))\n",
    "print(predicted_ratings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tells us that the knn recommender system would recommend jokes 63, 50, 53, 62, 89 to user 10. The predictions are based on users 52872, 36682, 22653"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid\n",
    "\n",
    "Above the train set was used to give some item predictions to a specific user using the cosine similarity distance measure and basing the prediction on 3 nearest neighbors. Now the valid set will be used to find the optimal nr of nearest neighbors and which measure distannce yields the best predictions. RMSE will be calculated using k = 5, 10, 20, 40 and with cosine or euclidean distance. \n",
    "\n",
    "Steps (for one k and one distance measure):\n",
    "1. two items will be taken out of the matrix and stored in another matrix (y)\n",
    "2. predictions will be created using the same logic as above but only for the items taken out in y (y_hat)\n",
    "3. RMSE will be calculated using y and y_hat\n",
    "<br>\n",
    "(ideally these steps could be repeated using two other items and calcluating the average RMSE, however, this wasn't possible now because of time constrains of the project)\n",
    "\n",
    "At the end the k value and distance with the lowest RMSE will be taken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>40470</th>\n",
       "      <th>12717</th>\n",
       "      <th>43541</th>\n",
       "      <th>54313</th>\n",
       "      <th>49565</th>\n",
       "      <th>4784</th>\n",
       "      <th>50262</th>\n",
       "      <th>10968</th>\n",
       "      <th>44198</th>\n",
       "      <th>16469</th>\n",
       "      <th>...</th>\n",
       "      <th>23291</th>\n",
       "      <th>15909</th>\n",
       "      <th>6848</th>\n",
       "      <th>11042</th>\n",
       "      <th>8949</th>\n",
       "      <th>3686</th>\n",
       "      <th>18807</th>\n",
       "      <th>10202</th>\n",
       "      <th>47540</th>\n",
       "      <th>21122</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43541</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54313</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49565</th>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId  40470  12717  43541  54313  49565  4784   50262  10968  44198  16469  \\\n",
       "userId                                                                         \n",
       "40470    1.00   0.36   0.24  -0.12  -0.11   0.28   0.48   0.23  -0.13  -0.06   \n",
       "12717    0.36   1.00   0.41  -0.54  -0.17   0.24   0.63   0.11  -0.31  -0.11   \n",
       "43541    0.24   0.41   1.00  -0.32  -0.08   0.33   0.46   0.05  -0.06  -0.12   \n",
       "54313   -0.12  -0.54  -0.32   1.00   0.46  -0.25  -0.49   0.09   0.46   0.03   \n",
       "49565   -0.11  -0.17  -0.08   0.46   1.00  -0.36  -0.33   0.08   0.70   0.00   \n",
       "\n",
       "userId  ...  23291  15909  6848   11042  8949   3686   18807  10202  47540  \\\n",
       "userId  ...                                                                  \n",
       "40470   ...   0.08   0.47   0.16   0.19  -0.04  -0.07  -0.37  -0.16   0.08   \n",
       "12717   ...   0.20   0.26   0.25   0.30  -0.29  -0.05  -0.35  -0.23   0.09   \n",
       "43541   ...   0.06   0.24   0.21   0.24  -0.22   0.08  -0.32  -0.02   0.13   \n",
       "54313   ...  -0.23   0.04  -0.26  -0.34   0.47   0.05   0.29   0.04  -0.16   \n",
       "49565   ...  -0.41   0.06  -0.13  -0.28   0.52  -0.18   0.19  -0.15   0.10   \n",
       "\n",
       "userId  21122  \n",
       "userId         \n",
       "40470    0.27  \n",
       "12717    0.24  \n",
       "43541    0.08  \n",
       "54313    0.03  \n",
       "49565    0.00  \n",
       "\n",
       "[5 rows x 5913 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the similarities between all users on the valid matrix using the cosine distance\n",
    "similarities_user_valid_cosine = cosine_similarity(valid)\n",
    "# transforming into a dataframe\n",
    "user_cosine_similarity_valid = pd.DataFrame(similarities_user_valid_cosine, index=valid.index, columns=valid.index)\n",
    "user_cosine_similarity_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>40470</th>\n",
       "      <th>12717</th>\n",
       "      <th>43541</th>\n",
       "      <th>54313</th>\n",
       "      <th>49565</th>\n",
       "      <th>4784</th>\n",
       "      <th>50262</th>\n",
       "      <th>10968</th>\n",
       "      <th>44198</th>\n",
       "      <th>16469</th>\n",
       "      <th>...</th>\n",
       "      <th>23291</th>\n",
       "      <th>15909</th>\n",
       "      <th>6848</th>\n",
       "      <th>11042</th>\n",
       "      <th>8949</th>\n",
       "      <th>3686</th>\n",
       "      <th>18807</th>\n",
       "      <th>10202</th>\n",
       "      <th>47540</th>\n",
       "      <th>21122</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43541</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54313</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49565</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId  40470  12717  43541  54313  49565  4784   50262  10968  44198  16469  \\\n",
       "userId                                                                         \n",
       "40470    1.00   0.03   0.02   0.02   0.02   0.02   0.03   0.02   0.02   0.02   \n",
       "12717    0.03   1.00   0.03   0.02   0.03   0.03   0.05   0.03   0.03   0.03   \n",
       "43541    0.02   0.03   1.00   0.02   0.03   0.03   0.04   0.03   0.03   0.03   \n",
       "54313    0.02   0.02   0.02   1.00   0.05   0.02   0.03   0.03   0.04   0.03   \n",
       "49565    0.02   0.03   0.03   0.05   1.00   0.02   0.04   0.04   0.07   0.04   \n",
       "\n",
       "userId  ...  23291  15909  6848   11042  8949   3686   18807  10202  47540  \\\n",
       "userId  ...                                                                  \n",
       "40470   ...   0.02   0.01   0.02   0.02   0.02   0.02   0.01   0.02   0.02   \n",
       "12717   ...   0.04   0.01   0.02   0.02   0.02   0.02   0.01   0.03   0.03   \n",
       "43541   ...   0.03   0.01   0.02   0.02   0.02   0.02   0.01   0.03   0.03   \n",
       "54313   ...   0.04   0.01   0.02   0.02   0.04   0.02   0.01   0.03   0.03   \n",
       "49565   ...   0.05   0.01   0.02   0.02   0.05   0.02   0.01   0.03   0.04   \n",
       "\n",
       "userId  21122  \n",
       "userId         \n",
       "40470    0.03  \n",
       "12717    0.03  \n",
       "43541    0.03  \n",
       "54313    0.03  \n",
       "49565    0.04  \n",
       "\n",
       "[5 rows x 5913 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the similarities between all users on the valid matrix using the euclidean distance\n",
    "similarities_user_valid_euclidean = euclidean_distances(valid)\n",
    "# converting the distance matrix to a similarity matrix, the idea is that the similarity between two points is high when their distance is low and vice versa\n",
    "similarities_user_valid_euclidean = 1 / (1 + similarities_user_valid_euclidean)\n",
    "# transforming into a dataframe\n",
    "user_euclidean_distance_valid = pd.DataFrame(similarities_user_valid_euclidean, index=valid.index, columns=valid.index)\n",
    "user_euclidean_distance_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking out items 7 and 15 and storing in y\n",
    "y = valid[[7, 15]].copy()\n",
    "\n",
    "# storing the user ids that have ranked both jokes 7 and 15 to a list\n",
    "valid_user_ids = y.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the prediction with 20 nearest neighbors and cosine distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_20_cosine = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    cosine_similarity_series = user_cosine_similarity_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 20 most similar users (k=20)\n",
    "    nearest_neighbors = ordered_similarities[1:21].index\n",
    "\n",
    "    # finding the ratings the 20 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_20 dictionary\n",
    "    y_hat_valid_20_cosine[user_id] = predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>6.18</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43541</th>\n",
       "      <td>6.08</td>\n",
       "      <td>6.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54313</th>\n",
       "      <td>-7.73</td>\n",
       "      <td>-5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49565</th>\n",
       "      <td>-6.22</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>-1.47</td>\n",
       "      <td>-3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18807</th>\n",
       "      <td>-7.68</td>\n",
       "      <td>-8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>-0.96</td>\n",
       "      <td>-4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47540</th>\n",
       "      <td>5.54</td>\n",
       "      <td>-6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21122</th>\n",
       "      <td>3.18</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId    7     15\n",
       "userId            \n",
       "40470   0.07 -1.31\n",
       "12717   6.18  6.78\n",
       "43541   6.08  6.02\n",
       "54313  -7.73 -5.29\n",
       "49565  -6.22  1.25\n",
       "...      ...   ...\n",
       "3686   -1.47 -3.09\n",
       "18807  -7.68 -8.39\n",
       "10202  -0.96 -4.10\n",
       "47540   5.54 -6.56\n",
       "21122   3.18  3.90\n",
       "\n",
       "[5913 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the dictionary into a df\n",
    "y_hat_valid_20_cosine = pd.DataFrame(y_hat_valid_20_cosine, index=valid.columns, columns=valid.index).copy()\n",
    "# transposing the matrix to match y\n",
    "y_hat_valid_20_cosine = y_hat_valid_20_cosine.T\n",
    "\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_20_cosine = y_hat_valid_20_cosine[[7,15]].copy()\n",
    "y_hat_valid_20_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46918</th>\n",
       "      <td>2.25</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>1.62</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58903</th>\n",
       "      <td>8.66</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61535</th>\n",
       "      <td>4.84</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58893</th>\n",
       "      <td>4.50</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25407</th>\n",
       "      <td>6.97</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28079</th>\n",
       "      <td>1.16</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20220</th>\n",
       "      <td>1.41</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46711</th>\n",
       "      <td>1.81</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24966</th>\n",
       "      <td>4.28</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41817</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42910</th>\n",
       "      <td>5.94</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34412</th>\n",
       "      <td>2.12</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61157</th>\n",
       "      <td>1.53</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26421</th>\n",
       "      <td>2.91</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19354</th>\n",
       "      <td>0.56</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>2.66</td>\n",
       "      <td>8.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3.69</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26212</th>\n",
       "      <td>3.94</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId    7    15\n",
       "userId           \n",
       "46918   2.25 6.06\n",
       "11577   1.62 5.28\n",
       "58903   8.66 4.56\n",
       "61535   4.84 8.69\n",
       "58893   4.50 3.78\n",
       "25407   6.97 6.38\n",
       "28079   1.16 3.34\n",
       "20220   1.41 4.00\n",
       "46711   1.81 0.19\n",
       "24966   4.28 3.69\n",
       "41817  -0.25 4.44\n",
       "42910   5.94 2.09\n",
       "34412   2.12 1.22\n",
       "61157   1.53 3.75\n",
       "26421   2.91 1.81\n",
       "22948   3.00 1.94\n",
       "19354   0.56 2.66\n",
       "36246   2.66 8.03\n",
       "23470   3.69 5.62\n",
       "26212   3.94 0.38"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the rows of the 20 closest neighbors \n",
    "valid.loc[nearest_neighbors, [7,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=20 and cosine similarity:  2.623369418115667\n"
     ]
    }
   ],
   "source": [
    "# calculating the rmse\n",
    "rmse_20_cosine = np.sqrt(mean_squared_error(y, y_hat_valid_20_cosine))\n",
    "print(\"Root mean squared error with k=20 and cosine similarity: \", rmse_20_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=20 and euclidean similarity:  2.3661257536571667\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 20 nearest neighbors and euclidean distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_20_euclidean = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users \n",
    "    euclidean_similarity_series = user_euclidean_distance_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = euclidean_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 20 most similar users (k=20)\n",
    "    nearest_neighbors = ordered_similarities[1:21].index\n",
    "\n",
    "    # finding the ratings the 20 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_20 dictionary\n",
    "    y_hat_valid_20_euclidean[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_20_euclidean = pd.DataFrame(y_hat_valid_20_euclidean, index=valid.columns, columns=valid.index)\n",
    "# transposing the matrix to match y\n",
    "y_hat_valid_20_euclidean = y_hat_valid_20_euclidean.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_20_euclidean = y_hat_valid_20_euclidean[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_20_euclidean = np.sqrt(mean_squared_error(y, y_hat_valid_20_euclidean))\n",
    "print(\"Root mean squared error with k=20 and euclidean similarity: \", rmse_20_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=5 and cosine similarity:  2.74982652564851\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 5 nearest neighbors and cosine similarity \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_5_cosine = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    cosine_similarity_series = user_cosine_similarity_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 5 most similar users (k=5)\n",
    "    nearest_neighbors = ordered_similarities[1:6].index\n",
    "\n",
    "    # finding the ratings the 5 closest neighbors gave\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean()\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_5 dictionary\n",
    "    y_hat_valid_5_cosine[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_5_cosine = pd.DataFrame(y_hat_valid_5_cosine)\n",
    "# transposing the matrix to match actual_ratings\n",
    "y_hat_valid_5_cosine = y_hat_valid_5_cosine.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_5_cosine = y_hat_valid_5_cosine[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_5_cosine = np.sqrt(mean_squared_error(y, y_hat_valid_5_cosine))\n",
    "print(\"Root mean squared error with k=5 and cosine similarity: \", rmse_5_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=5 and euclidean similarity:  2.3549109788702243\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 5 nearest neighbors and euclidean distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_5_euclidean = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    euclidean_similarity_series = user_euclidean_distance_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = euclidean_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 5 most similar users (k=5)\n",
    "    nearest_neighbors = ordered_similarities[1:6].index\n",
    "\n",
    "    # finding the ratings the 5 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_5 dictionary\n",
    "    y_hat_valid_5_euclidean[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_5_euclidean = pd.DataFrame(y_hat_valid_5_euclidean, index=valid.columns, columns=valid.index)\n",
    "# transposing the matrix to match y\n",
    "y_hat_valid_5_euclidean = y_hat_valid_5_euclidean.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_5_euclidean = y_hat_valid_5_euclidean[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_5_euclidean = np.sqrt(mean_squared_error(y, y_hat_valid_5_euclidean))\n",
    "print(\"Root mean squared error with k=5 and euclidean similarity: \", rmse_5_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=10 and cosine similarity:  2.6316820610530556\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 10 nearest neighbors and cosine similarity \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_10_cosine = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users \n",
    "    cosine_similarity_series = user_cosine_similarity_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 10 most similar users (k=10)\n",
    "    nearest_neighbors = ordered_similarities[1:11].index\n",
    "\n",
    "    # finding the ratings the 10 closest neighbors gave\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean()\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_10 dictionary\n",
    "    y_hat_valid_10_cosine[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_10_cosine = pd.DataFrame(y_hat_valid_10_cosine)\n",
    "# transposing the matrix to match actual_ratings\n",
    "y_hat_valid_10_cosine = y_hat_valid_10_cosine.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_10_cosine = y_hat_valid_10_cosine[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_10_cosine = np.sqrt(mean_squared_error(y, y_hat_valid_10_cosine))\n",
    "print(\"Root mean squared error with k=10 and cosine similarity: \", rmse_10_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=10 and euclidean similarity:  2.3136017201883257\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 10 nearest neighbors and euclidean distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_10_euclidean = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    euclidean_similarity_series = user_euclidean_distance_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = euclidean_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 10 most similar users (k=10)\n",
    "    nearest_neighbors = ordered_similarities[1:11].index\n",
    "\n",
    "    # finding the ratings the 10 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_10 dictionary\n",
    "    y_hat_valid_10_euclidean[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_10_euclidean = pd.DataFrame(y_hat_valid_10_euclidean, index=valid.columns, columns=valid.index)\n",
    "# transposing the matrix to match y\n",
    "y_hat_valid_10_euclidean = y_hat_valid_10_euclidean.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_10_euclidean = y_hat_valid_10_euclidean[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_10_euclidean = np.sqrt(mean_squared_error(y, y_hat_valid_10_euclidean))\n",
    "print(\"Root mean squared error with k=10 and euclidean similarity: \", rmse_10_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=40 and cosine similarity:  2.669310344517062\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 40 nearest neighbors and cosine similarity \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_40_cosine = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    cosine_similarity_series = user_cosine_similarity_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 40 most similar users (k=40)\n",
    "    nearest_neighbors = ordered_similarities[1:41].index\n",
    "\n",
    "    # finding the ratings the 40 closest neighbors gave\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean()\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_40 dictionary\n",
    "    y_hat_valid_40_cosine[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_40_cosine = pd.DataFrame(y_hat_valid_40_cosine)\n",
    "# transposing the matrix to match actual_ratings\n",
    "y_hat_valid_40_cosine = y_hat_valid_40_cosine.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_40_cosine = y_hat_valid_40_cosine[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_40_cosine = np.sqrt(mean_squared_error(y, y_hat_valid_40_cosine))\n",
    "print(\"Root mean squared error with k=40 and cosine similarity: \", rmse_40_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=40 and euclidean similarity:  2.468245907471982\n"
     ]
    }
   ],
   "source": [
    "## getting the prediction with 40 nearest neighbors and euclidean distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat_valid_40_euclidean = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in valid_user_ids:\n",
    "    # finding the similarity values for all users \n",
    "    euclidean_similarity_series = user_euclidean_distance_valid.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = euclidean_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 40 most similar users (k=40)\n",
    "    nearest_neighbors = ordered_similarities[1:41].index\n",
    "\n",
    "    # finding the ratings the 40 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = valid.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_valid_40 dictionary\n",
    "    y_hat_valid_40_euclidean[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat_valid_40_euclidean = pd.DataFrame(y_hat_valid_40_euclidean, index=valid.columns, columns=valid.index)\n",
    "# transposing the matrix to match y\n",
    "y_hat_valid_40_euclidean = y_hat_valid_40_euclidean.T\n",
    "# extracting only predictions for items 7 and 15\n",
    "y_hat_valid_40_euclidean = y_hat_valid_40_euclidean[[7,15]].copy()\n",
    "\n",
    "# calculating the rmse\n",
    "rmse_40_euclidean = np.sqrt(mean_squared_error(y, y_hat_valid_40_euclidean))\n",
    "print(\"Root mean squared error with k=40 and euclidean similarity: \", rmse_40_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest RMSE value is with k=10, distance=euclidean with a value of 2.3136017201883257\n"
     ]
    }
   ],
   "source": [
    "mse_dict = {'k=40, distance=euclidean': rmse_40_euclidean, 'k=40, distance=cosine': rmse_40_cosine, 'k=10, distance=euclidean': rmse_10_euclidean, 'k=10, distance=cosine': rmse_10_cosine, 'k=20, distance=euclidean': rmse_20_euclidean, 'k=20, distance=cosine': rmse_20_cosine, 'k=5, distance=euclidean': rmse_5_euclidean, 'k=5, distance=cosine': rmse_5_cosine}\n",
    "min_mse_name = min(mse_dict, key=mse_dict.get)\n",
    "print(f\"The smallest RMSE value is with {min_mse_name} with a value of {mse_dict[min_mse_name]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Ideally, now the knn model would be fitted using the k and distance measure determined from above, however, it wasn't possible to calculate the user-user similarties using the euclidean distances as it took too much computational power this computer can take and gave a memory error. Therefore, now the best k using cosine similarity needs to be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest RMSE value is with k=20, distance=cosine with a value of 2.623369418115667\n"
     ]
    }
   ],
   "source": [
    "mse_dict = {'k=40, distance=cosine': rmse_40_cosine, 'k=10, distance=cosine': rmse_10_cosine, 'k=20, distance=cosine': rmse_20_cosine, 'k=5, distance=cosine': rmse_5_cosine}\n",
    "min_mse_name = min(mse_dict, key=mse_dict.get)\n",
    "print(f\"The smallest RMSE value is with {min_mse_name} with a value of {mse_dict[min_mse_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recommended to user 10 in order:\n",
      "jokeId\n",
      "62   7.52\n",
      "50   7.11\n",
      "89   6.93\n",
      "32   6.89\n",
      "63   6.72\n",
      "dtype: float64\n",
      "based on neighbors: Int64Index([28079, 46711, 34412, 20220, 11577, 26421, 26212, 23291, 23332,\n",
      "            50752, 40947, 22948,  3428, 36246, 28256, 19354, 61399, 28315,\n",
      "            61157, 21310, 48989, 21640, 40542, 41439, 61694, 42851, 17212,\n",
      "            23641, 51473, 23150, 25878, 21297, 58255, 22418, 21337, 62312,\n",
      "            11071, 17039, 44679, 11999],\n",
      "           dtype='int64', name='userId')\n"
     ]
    }
   ],
   "source": [
    "## finding recommendations for a specific user using the cosine similarity \n",
    "\n",
    "user_id = 10\n",
    "num_neighbors = 20\n",
    "num_recommendations = 5\n",
    "predicted_ratings = make_recommendations(user_id, train, user_cosine_similarity_train, num_neighbors, num_recommendations)\n",
    "\n",
    "print('Items recommended to user {} in order:'.format(user_id))\n",
    "print(predicted_ratings)\n",
    "print('based on neighbors:', nearest_neighbors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Now to test how accurate the predictions are the model will be fitted on the test matrix and applying the same logic as when finding the bet k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1783</th>\n",
       "      <th>8048</th>\n",
       "      <th>63051</th>\n",
       "      <th>36205</th>\n",
       "      <th>37168</th>\n",
       "      <th>38579</th>\n",
       "      <th>57695</th>\n",
       "      <th>2993</th>\n",
       "      <th>27747</th>\n",
       "      <th>37030</th>\n",
       "      <th>...</th>\n",
       "      <th>15846</th>\n",
       "      <th>23292</th>\n",
       "      <th>7787</th>\n",
       "      <th>36652</th>\n",
       "      <th>19772</th>\n",
       "      <th>34289</th>\n",
       "      <th>4447</th>\n",
       "      <th>34850</th>\n",
       "      <th>45873</th>\n",
       "      <th>38308</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63051</th>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36205</th>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37168</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId  1783   8048   63051  36205  37168  38579  57695  2993   27747  37030  \\\n",
       "userId                                                                         \n",
       "1783     1.00  -0.21   0.21   0.25   0.10   0.26  -0.14   0.16  -0.01   0.21   \n",
       "8048    -0.21   1.00  -0.27  -0.49  -0.32  -0.64   0.56   0.00   0.02  -0.13   \n",
       "63051    0.21  -0.27   1.00   0.05   0.14   0.35  -0.04  -0.08   0.08  -0.02   \n",
       "36205    0.25  -0.49   0.05   1.00   0.12   0.12  -0.06   0.12   0.11   0.06   \n",
       "37168    0.10  -0.32   0.14   0.12   1.00   0.21   0.04  -0.14   0.29   0.17   \n",
       "\n",
       "userId  ...  15846  23292  7787   36652  19772  34289  4447   34850  45873  \\\n",
       "userId  ...                                                                  \n",
       "1783    ...  -0.22  -0.07   0.20  -0.03   0.16   0.00  -0.09   0.14   0.05   \n",
       "8048    ...   0.18   0.23  -0.12   0.16  -0.78  -0.55   0.18   0.05  -0.08   \n",
       "63051   ...   0.02  -0.06   0.03  -0.04   0.19   0.05   0.09   0.03   0.04   \n",
       "36205   ...  -0.23   0.09   0.08  -0.18   0.60   0.25  -0.69   0.13   0.13   \n",
       "37168   ...   0.08  -0.03   0.27   0.03   0.17   0.05   0.17   0.24  -0.13   \n",
       "\n",
       "userId  38308  \n",
       "userId         \n",
       "1783    -0.18  \n",
       "8048     0.25  \n",
       "63051   -0.01  \n",
       "36205   -0.02  \n",
       "37168   -0.17  \n",
       "\n",
       "[5 rows x 5913 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the similarities between all users on the original matrix\n",
    "similarities_user_test = cosine_similarity(test)\n",
    "\n",
    "# storing the above similarities in a dataframe, code inspired from DataCamp\n",
    "user_cosine_similarity_test = pd.DataFrame(similarities_user_test, index=test.index, columns=test.index)\n",
    "user_cosine_similarity_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking out items 120 and 88 and storing in y\n",
    "y = valid[[120, 88]].copy()\n",
    "# storing the user ids\n",
    "test_user_ids = test.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the prediction with 20 nearest neighbors and cosine distance \n",
    "\n",
    "# initializing an empty dictionary to store predicted rankings \n",
    "y_hat = {}\n",
    "\n",
    "# looping over all users in the test_user_ids list\n",
    "for user_id in test_user_ids:\n",
    "    # finding the similarity values for all users\n",
    "    cosine_similarity_series = user_cosine_similarity_test.loc[user_id]\n",
    "\n",
    "    # sorting the values from highest to lowest\n",
    "    ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "    # finding 20 most similar users (k=20)\n",
    "    nearest_neighbors = ordered_similarities[1:21].index\n",
    "\n",
    "    # finding the ratings the 20 closest neighbors gave and calculating the mean\n",
    "    neighbor_ratings = test.reindex(nearest_neighbors)\n",
    "    predicted_rating = neighbor_ratings.mean().sort_values(ascending=False)\n",
    "\n",
    "    # storing the predicted rating for the current user in the predicted_rankings_test_20 dictionary\n",
    "    y_hat[user_id] = predicted_rating\n",
    "\n",
    "# transforming the dictionary into a df\n",
    "y_hat = pd.DataFrame(y_hat, index=test.columns, columns=test.index).copy()\n",
    "# transposing the matrix to match y\n",
    "y_hat = y_hat.T\n",
    "\n",
    "# extracting only predictions for items 120, 88\n",
    "y_hat = y_hat[[120, 88]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error with k=20 and cosine similarity:  2.891830213857846\n"
     ]
    }
   ],
   "source": [
    "# calculating the rmse\n",
    "rmse = np.sqrt(mean_squared_error(y, y_hat))\n",
    "print(\"Root mean squared error with k=20 and cosine similarity: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8618efa98ab0d8052f88198fede59be707389e724f3c53773e23d23d35d507f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
